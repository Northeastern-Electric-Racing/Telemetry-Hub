""" use main.py file to see example, take the data from the file and run the processing tests and store the data in a list"""
import multiprocessing
from datetime import datetime

from os import listdir, path
import csv
from typing import List

from ner_processing.master_mapping import DATA_IDS
from ner_processing.thread import thread

FORMAT_DIRECTORY = "format1-valid.txt"
OUTPUT_PATH = "./output.csv"
PROCESSORS = 8
PROCESS_CHUNK_SIZE = 85000  # Processes data in chunks, specified by this variable

def find_time(start, finish):
    """
    Prints the difference between the two times provided
    Both inputs are lists of strings:
        - minutes being the zeroth index of the list
        - seconds being the first index of the list
        - microseconds being the second index of the list
    """

    minutes = int(finish[0]) - int(start[0])
    seconds = int(finish[1]) - int(start[1])
    microseconds = int(finish[2]) - int(start[2])

    if microseconds < 0:
        seconds -= 1
        microseconds += 1000000

    if seconds < 0:
        minutes -= 1
        seconds += 60

    print("Time to process (Minutes:Seconds.Microseconds): " + str(minutes) + ":" + str(seconds) + "." + str(
        microseconds))


def process_lines(lines, writer):
    with multiprocessing.Pool(PROCESSORS) as p:
        out = p.map(thread, lines)
    lines.clear()
    for data in out:
        for sub_data in data:
            str_time = sub_data.timestamp.toString("yyyy-MM-ddTHH:mm:ss.zzzZ")
            writer.writerow([str_time, sub_data.id, DATA_IDS[sub_data.id], sub_data.value])


if __name__ == "__main__":
    """
    Processes the log files in the log folder and puts them in the output.csv file
    """

    start_time = datetime.now().strftime("%M:%S:%f").split(":")
    current_line = 0
    manager = multiprocessing.Manager()
    return_dict = manager.dict()

    print(f"Writing to the CSV")
    header = ["time", "data_id", "description", "value"]

    with open(OUTPUT_PATH, "w", encoding="UTF8", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(header)

        data = []
        for fp in listdir(FORMAT_DIRECTORY):
            with open(FORMAT_DIRECTORY + fp) as file:
                line_num = 0
                lines = []
                for line in file:
                    line_num += 1
                    current_line += 1
                    if current_line % 5000 == 0:
                        print(f"Line {line_num}")

                    lines.append(line)
                    try:
                        if line_num % PROCESS_CHUNK_SIZE == 0:
                            """
                            When stored data reaches specified amount, use threads to decode data faster
                            """
                            process_lines(lines, writer)

                    except:
                        print(f"Error with line {line_num} in file {file.name}")
                        pass

                if lines:
                    """
                    Handles leftover stored lines when the loop ends
                    """
                    process_lines(lines, writer)

    finish_time = datetime.now().strftime("%M:%S:%f").split(":")
    find_time(start_time, finish_time)
